import yfinance as yf
import pandas as pd
import time
import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import requests

# ===========================
# 1. è¨­å®šå€
# ===========================

# Google Sheet ç¶²å€
SHEET_URL = 'https://docs.google.com/spreadsheets/d/1mvC4i7Pw7uxS-OV5bav0uhvb6tAvRufTataFzwQQ2Ic/edit?usp=sharing'
SHEET_NAME = 'rsi_scanner_us'

# æ¿¾ç¶²è¨­å®š (æ­£å¼ç‰ˆ)
MIN_PRICE = 5.0             # è‚¡åƒ¹ > 5 ç¾å…ƒ
MIN_VOLUME_SHARES = 200000  # æˆäº¤é‡ > 20 è¬è‚¡

# é‡‘é‘°è·¯å¾‘
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
JSON_FILE = os.path.join(BASE_DIR, 'service_account.json')

# ===========================
# 2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
# ===========================
def calculate_sma(series, length):
    return series.rolling(window=length).mean()

def calculate_rsi(series, length=100):
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ma_up = up.ewm(alpha=1/length, adjust=False).mean()
    ma_down = down.ewm(alpha=1/length, adjust=False).mean()
    rs = ma_up / ma_down
    rsi = 100 - (100 / (1 + rs))
    return rsi

# ===========================
# 3. Google Sheet å­˜æª” (åªå­˜ æ—¥æœŸ/ä»£è™Ÿ/åç¨±)
# ===========================
def update_rolling_data(new_data_list):
    print("\næ­£åœ¨é€£ç·š Google Sheet æ›´æ–°è³‡æ–™...")
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_name(JSON_FILE, scope)
        client = gspread.authorize(creds)
        sheet = client.open_by_url(SHEET_URL)
        
        try:
            ws = sheet.worksheet(SHEET_NAME)
        except gspread.WorksheetNotFound:
            # å»ºç«‹æ–°å·¥ä½œè¡¨ï¼Œåªç•™ 3 æ¬„
            ws = sheet.add_worksheet(title=SHEET_NAME, rows="2000", cols="3")
            ws.append_row(["æ—¥æœŸ", "ä»£è™Ÿ", "åç¨±"])

        all_rows = ws.get_all_values()
        if len(all_rows) <= 1:
            header = ["æ—¥æœŸ", "ä»£è™Ÿ", "åç¨±"]
            existing_data = []
        else:
            header = all_rows[0]
            existing_data = all_rows[1:]

        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        today_rows = []
        
        for stock in new_data_list:
            # ç°¡åŒ–æ¬„ä½ï¼Œåªå­˜é€™ä¸‰å€‹
            row = [today_str, stock['ticker'], stock['name']]
            today_rows.append(row)

        clean_history = [row for row in existing_data if row[0] != today_str]
        final_data = clean_history + today_rows
        
        # åªä¿ç•™æœ€è¿‘ 3 å¤©
        unique_dates = sorted(list(set([row[0] for row in final_data])), reverse=True)
        if len(unique_dates) > 3:
            keep_dates = unique_dates[:3]
            final_data = [row for row in final_data if row[0] in keep_dates]
        
        ws.clear()
        ws.append_row(header)
        if final_data:
            ws.append_rows(final_data)
        print(f"âœ… æ›´æ–°å®Œæˆï¼å¯«å…¥ {len(today_rows)} ç­†è³‡æ–™ (åƒ…ä¿ç•™æ—¥æœŸ/ä»£è™Ÿ/åç¨±)ã€‚")

    except Exception as e:
        print(f"âŒ å­˜æª”å¤±æ•—: {e}")

# ===========================
# 4. å–å¾—è‚¡ç¥¨æ¸…å–® (S&P 500 + 400)
# ===========================
def get_target_tickers():
    print("æ­£åœ¨å¾ Wikipedia æŠ“å– S&P 500 èˆ‡ S&P 400 æ¸…å–®...")
    tickers = []
    names = {}
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36"
    }

    try:
        # S&P 500
        url_500 = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        r_500 = requests.get(url_500, headers=headers)
        df500 = pd.read_html(r_500.text)[0]
        for _, row in df500.iterrows():
            sym = row['Symbol'].replace('.', '-')
            tickers.append(sym)
            names[sym] = row['Security']
            
        # S&P 400
        url_400 = 'https://en.wikipedia.org/wiki/List_of_S%26P_400_companies'
        r_400 = requests.get(url_400, headers=headers)
        df400 = pd.read_html(r_400.text)[0]
        
        col_sym = 'Symbol' if 'Symbol' in df400.columns else df400.columns[0]
        col_name = 'Security' if 'Security' in df400.columns else df400.columns[1]
        
        for _, row in df400.iterrows():
            sym = str(row[col_sym]).replace('.', '-')
            if sym not in tickers:
                tickers.append(sym)
                names[sym] = str(row[col_name])

        print(f"âœ… æ¸…å–®å–å¾—æˆåŠŸï¼Œå…± {len(tickers)} æª”è‚¡ç¥¨ã€‚")
        return tickers, names
    except Exception as e:
        print(f"âŒ ç„¡æ³•å–å¾—æ¸…å–®: {e}")
        return [], {}

def check_stock(ticker, company_name):
    try:
        df = yf.download(ticker, period="2y", interval="1d", progress=False)
        
        if df.empty or len(df) < 300: return None
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)

        today = df.iloc[-1]
        prev  = df.iloc[-2]
        
        if today['Close'] < MIN_PRICE: return None
        if today['Volume'] < MIN_VOLUME_SHARES: return None

        df['RSI'] = calculate_rsi(df['Close'], length=100)
        df['RSI_SMA'] = calculate_sma(df['RSI'], length=200)

        df['MA20']  = calculate_sma(df['Close'], length=20)
        df['MA60']  = calculate_sma(df['Close'], length=60)
        df['MA120'] = calculate_sma(df['Close'], length=120)
        df['MA240'] = calculate_sma(df['Close'], length=240)
        
        today = df.iloc[-1]
        prev  = df.iloc[-2]

        cond_rsi = (today['RSI'] > today['RSI_SMA'])
        above_all_now = (
            today['Close'] > today['MA20'] and 
            today['Close'] > today['MA60'] and 
            today['Close'] > today['MA120'] and 
            today['Close'] > today['MA240']
        )
        above_all_prev = (
            prev['Close'] > prev['MA20'] and 
            prev['Close'] > prev['MA60'] and 
            prev['Close'] > prev['MA120'] and 
            prev['Close'] > prev['MA240']
        )
        
        cond_first_day = above_all_now and (not above_all_prev)

        if cond_rsi and cond_first_day:
            return {
                "ticker": ticker, 
                "name": company_name
            }
        return None
    except Exception:
        return None

# ===========================
# 5. ä¸»ç¨‹å¼åŸ·è¡Œ
# ===========================
if __name__ == "__main__":
    if not os.path.exists(JSON_FILE):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° {JSON_FILE}")
        exit()

    tickers, name_map = get_target_tickers()
    if not tickers: exit()

    found_stocks = []
    print(f"\n=== é–‹å§‹æƒæç¾è‚¡ (S&P 500+400) ===")
    
    start_time = time.time()

    for i, ticker in enumerate(tickers):
        if i % 10 == 0: print(".", end="", flush=True) # ç°¡æ˜“é€²åº¦æ¢
            
        c_name = name_map.get(ticker, ticker)
        res = check_stock(ticker, c_name)
        
        if res:
            print(f"\nğŸ”¥ ç™¼ç¾: {res['ticker']} ({res['name']})")
            found_stocks.append(res)
        
        time.sleep(0.5)

    end_time = time.time()
    duration = (end_time - start_time) / 60
    
    print("\n" + "="*30)
    print(f"ğŸ‰ æƒæå®Œæˆï¼è€—æ™‚ {duration:.1f} åˆ†é˜ã€‚")
    print(f"å…±æ‰¾åˆ° {len(found_stocks)} æª”ã€‚")
    
    if found_stocks:
        update_rolling_data(found_stocks)
    else:
        print("ä»Šæ—¥ç„¡ç¬¦åˆæ¢ä»¶è‚¡ç¥¨ã€‚")